\documentclass[11pt,a4paper,openbib]{article}
\usepackage[latin1]{inputenc}
\usepackage{bm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{physics}
\usepackage[margin=1.25in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\usepackage{amsmath}
\numberwithin{equation}{section}
\linespread{1.3}


\begin{document}
  \pagenumbering{arabic}
\begin{center}
\LARGE{Hamiltonian Control of Open Gaussian Systems}

\large{Rianna Kelly}
\end{center}

\begin{abstract}

\end{abstract}

\section{Introduction}


\subsection{The Density Operator}
\label{sec:densityop}
We begin by summarising the Dirac formalism of quantum mechanics and motivating the need for a density operator approach to open systems. It is a fundamental postulate of quantum mechanics that the state vector, $\ket{\psi}$, provides a complete physical description of the system.  To any physical system, we associate a Hilbert space (the `state space'), which represents the entire set of states that the state vector can take. Operators are taken to act on elements of the Hilbert space, mapping each vector to some other vector within the space. Of particular importance are the `observable operators' which make precise our notion of measurement; every physically observable quantity has, associated with it, a linear Hermitian operator whose (real) eigenvalues represent possible outcomes of a measurement \cite{vonNeumann55}. We refer to `possible outcomes' to emphasise that, at its core, quantum mechanics is inherently probabilistic and measurements are typically described in terms of their expectation values.

Of course, in the real world, it is rare to have complete knowledge of a system. Alongside quantum mechanical uncertainty, there may also be classical uncertainties relating to what state the system is actually assumed to be in. For instance, uncertainties in an experimental setup could be known to generate any of $n$ possible states, $\ket{\psi_n}$, each with a probability $p_n$. Our expectation of any measurement would then be a function of two unknowns: the inherent quantum mechanical uncertainty associated with any measurement of the state $\ket{\psi_n}$, as well as the classical uncertainty relating to which of the $n$ possible states the system is in at the moment of measurement. This `statistical mixture' of unknowns can be completely captured by introducing the density operator, $\hat{\rho}$, which we define \cite{Fano57}

\begin{equation} \label{eq:1}
\hat{\rho} = \sum_{j=1}^{n} p_j \ket{\psi_j}\bra{\psi_j}.
\end{equation}

The density operator represents our best description of the system and can, for all practical purposes, be regarded as the state of the system (in place of the state vector $\ket{\psi}$). To avoid confusion, we note at the offset that the density operator can, when equipped with a basis that is discrete and finite, be represented by a matrix and we shall use the terms density matrix and density operator interchangeably.

From our definition \ref{eq:1}, it follows that the density matrix is both positive semi-definite, 
\begin{equation} \label{eq:2}
\hat{\rho} \geq 0,
\end{equation}
and Hermitian,
\begin{equation} \label{eq:3}
\hat{\rho} = \hat{\rho}^\dagger .
\end{equation}
It can also be shown to have unit trace, 
\begin{equation} \label{eq:4}
\Tr[\hat{\rho}] = 1.
\end{equation}

As stated above, the main drive behind using a density operator approach stems from our desire to completely describe systems, accounting for all sources of uncertainty. It can be shown that the expectation value of any observable operator, $\hat{O}$, can be written as
\begin{equation} \label{eq:5}
\Tr[\hat{O}\hat{\rho}].
\end{equation}

This equation neatly captures all of the measurable/observable uncertainties of the system and, therefore, justifies our usage of density operators.

\subsection{Discrete Variable Systems}
\color{red}AS says to remove this section \color{black}Our focus in this report is on CV systems. Before discussing those, however, it is worth briefly noting that discrete variable systems exist and arise frequently in quantum mechanics. As the name suggests, discrete variable systems are ones in which the possible outcomes of a measurement are discrete (or quantised). This manifests itself mathematically via operators whose eigenvalues are discrete. If, in addition to being discrete, the eigenvalues form a finite set, the system can be handled using matrix vector methods. There are numerous examples of discrete variable systems such as \color{red} the energy levels of a quantum harmonic oscillator (infinite dimensional Hilbert space) or \color{black}the spin of an electron (two dimensional Hilbert space).

\section{Continuous Variable Systems}
\label{sec:cvs}
Eigenvalues (observable values) of a system can also have a continuous spectra which naturally implies that the associated Hilbert space is infinite dimensional. Perhaps, the most obvious examples are the position or momentum of a particle. Noting that any measurement of, say, position must be an eigenvalue of the position operator it must follow that the state space is infinite in extent. 

CV systems are quantum systems described by a pair of canonical operators, i.e. the pair are related via a Fourier transform. Position and momentum are one such example of a canonical/conjugate pair. Canonical pairs satisfy the canonical commutation relation which, for position and momentum, can be written \cite{Serafini05}
\begin{equation} \label{eq:6}
[\hat{x}, \hat{p}] = i\hbar\hat{\mathbb{I}}.
\end{equation}

One of the most fundamental examples of a CV system is the quantum harmonic oscillator which describes the dynamics of a particle in a quadratic potential. The Hamiltonian can be written as \cite{Adesso14, Braunstein}
\begin{equation} \label{eq:7}
\hat{H} = \frac{\hat{p}^2}{2m} + \frac{1}{2} m\omega^2\hat{x}^2,
\end{equation}

where $m$ is taken to be the mass of the particle and $\omega$, the angular frequency. For a system with $N$ non-interacting modes, the Hamiltonian can be written as a sum of the individual Hamiltonians 

\begin{equation} \label{eq:8}
\hat{H} = \sum_{k=1}^{N}\hat{H_k},\qquad\hat{H_k} =\frac{\hat{p_k}^2}{2m} + \frac{1}{2} m\omega_{k}^2\hat{x_k}^2.
\end{equation}
Here, $\hat{x_k}$ and $\hat{p_k}$ are canonical pairs satisfying the canonical commutation relation 
\begin{equation} \label{eq:9}
[\hat{x_j}, \hat{p_k}] = i\hbar \delta_{j\,k}\hat{\mathbb{I}} .
\end{equation}
It is convenient to group these operators into a single vector defined
\begin{equation} \label{eq:10}
\mathbf{\hat{r}} = (\hat{x_1},\hat{p_1},\hat{x_2},\hat{p_2},...,\hat{x_N},\hat{p_N})^T = (\hat{r}_1, \hat{r}_2, ..., \hat{r}_{2N})^T .
\end{equation}
From which the following commutation relations can be derived (using Eq.\ref{eq:6})
\begin{equation*}
[\hat{r}_1, \hat{r}_1] = [\hat{x_1}, \hat{x_2}] = 0,
\end{equation*} 
\begin{equation*}
[\hat{r}_1, \hat{r}_2] = [\hat{x_1}, \hat{p_1}] = i,
\end{equation*} 
\begin{equation*}
[\hat{r}_2, \hat{r}_1] = [\hat{p_1}, \hat{x_1}] = -i,
\end{equation*} 
\begin{equation*}
[\hat{r}_2, \hat{r}_2] = [\hat{p_1}, \hat{p_2}] = 0,
\end{equation*}
which gives the matrix 
\begin{equation*}
\begin{pmatrix}
0 & i  \\
-i & 0 \\
\end{pmatrix}.
\end{equation*}
Then the canonical commutation relation can be written as
\begin{equation} \label{eq:11}
[\hat{r_j}, \hat{r_k}] = i\Omega_{jk}\mathbb{\hat{I}},
\end{equation}
where $\Omega$ is a $2N \times 2N$, anti-symmetric matrix known as the symplectic form. It can be written as a matrix direct sum as follows
\begin{equation} \label{eq:12}
\Omega = \bigoplus_{j=1}^{N}\omega, \qquad\omega = 
\begin{pmatrix}
0 & 1  \\
-1 & 0 \\
\end{pmatrix}.
\end{equation}

The symplectic form is of considerable importance within CV systems, specifically within a set of states known as Gaussian states. The symplectic framework and Gaussian states are discussed in detail in \ref{sec:gaussian}. 

\subsection{Phase Space Representation}

As noted in Section \ref{sec:densityop}, the state of a quantum system can be represented using a density operator approach. Additionally, we can use $\hat{\rho}$ to build a phase space representation of the system where a real distribution is defined over the $2N$ dimensions in that space. 

To transition between the representations, we must first introduce the  Weyl displacement operator, $\hat{D}_\textbf{r}$, \cite{Olivares12}
\begin{equation} \label{eq:13}
\hat{D}_\mathbf{r} = e^{i\mathbf{r}^{T}\Omega\mathbf{\hat{r}}}, 
\end{equation}

where $\mathbf{r} = (x_1, p_1, ..., x_N, p_N)^T $ represents a point in phase space and $\mathbf{\hat{r}}$ is the vector of canonical operators already introduced. As the name suggests, the displacement operator, $\hat{D}_\mathbf{r}$, shifts the state of the system by an amount $\mathbf{r}$ in phase space. The action of this is shown in Figure \ref{fig:RKPOINT}. 

It can be shown that the set of all displacement operators, $\hat{D}_\mathbf{r}$, for all $\mathbf{r}$ within the phase space, form a basis in operator space, i.e. any operator can be represented as a linear combination of displacement operators. Given $\mathbf{r}$ varies continuously within the phase space, it is not surprising that the linear combination is represented via an integral; an arbitrary operator, $\hat{O}$, can be represented as a Fourier-Weyl transform \cite{Cahill68}
\begin{equation} \label{eq:14}
\hat{O} = \frac{1}{(2\pi)^n}\int \chi(\mathbf{r})\hat{D}_\textbf{r}  d\textbf{r} = \frac{1}{(2\pi)^n} \int \Tr[\hat{D}_\textbf{r}^\dagger\hat{O}]\hat{D}_\textbf{r}  d\textbf{r}, \qquad \hat{D}_\mathbf{r}^\dagger  = \hat{D}_\mathbf{-r}.
\end{equation}  

Here, $\chi(\mathbf{r})$ can be interpreted as a function that modulates the amplitude of $\hat{D}_\textbf{r}$. This equally well applies to an arbitrary quantum state, which can be written using a density operator
\begin{equation} \label{eq:15}
\hat{\rho} = \frac{1}{(2\pi)^n} \int \chi_\rho(\mathbf{r})\hat{D}_\textbf{r}  d\textbf{r} = \frac{1}{(2\pi)^n} \int \Tr[\hat{D}_\textbf{r}^\dagger \hat{\rho}]\hat{D}_\textbf{r}  d\textbf{r}.
\end{equation} 

\begin{figure}
	\centering
	\includegraphics[scale = 1]{RKPOINT}
	\caption{The displacement operator, $\hat{D}_\mathbf{r}$, shifts the state of the system in phase space.}
	\label{fig:RKPOINT}
\end{figure}

The action of this is shown in Figure \ref{fig:RKDENSITY}. We refer to $\chi_\rho$ as the characteristic function and, for every quantum state, $\hat{\rho}$, a corresponding characteristic function, $\chi_\rho$, exists \cite{Hillery84}. The characteristic function of the density operator is crucial to the definition of a Gaussian state, which is a key focus of this paper.

\begin{figure}
	\centering
	\includegraphics[scale = 1]{RKDENSITY}
	\caption{ The state of the system can be represented as a linear combination of displacement operators whose amplitude is modulated by the characteristic function.}
	\label{fig:RKDENSITY}
\end{figure}


\section{Gaussian States}
\label{sec:gaussian} 
\subsection{Definition and Interpretation}

A Gaussian state is one in which the characteristic function is Gaussian. The utility of such a description comes about from the relatively few parameters required to characterise this state. A one dimension Gaussian distribution is completely characterised by its first and second moments (the mean and variance) \cite{Ribeiro}. The generalisation to a $2N$ dimensional phase space is straightforward; the Gaussian state is completely characterised by a $2N$ dimensional vector of means and a $2N\times2N$ covariance matrix. The use of Gaussian states makes the handling of CV systems significantly more mathematically manageable.

For $x \in \mathbb{R}^{2N}$, the standard Gaussian function can be written as \cite{Adesso14}
\begin{equation} \label{eq:16}
f(x) = Ae^{-\frac{1}{2}x^{T}Bx+ x^{T} y},
\end{equation}
where B is a $2N \times 2N$ matrix and $y$ is the mean vector. A quantum state $\hat{\rho}$ is Gaussian if and only if its characteristic function $\chi_\rho$ is a Gaussian function in phase space \cite{Schumaker86}, that is to say $\chi_\rho$ is of the form
\begin{equation} \label{eq:17}
\chi_G(\mathbf{r}) = e^{-\frac{1}{4}(\Omega^T\mathbf{r})^T\sigma(\Omega^T\mathbf{r}) - i(\Omega^T\mathbf{r})^T\mathbf{\bar{r}}},
\end{equation} where $\sigma$ is taken to be the covariance matrix and $\mathbf{\bar{r}}$ is the vector of first moments. Written explicitly \cite{Adesso14},
\begin{equation} \label{eq:18}
\mathbf{\bar{r}} = (\langle\hat{x_1}\rangle, \langle\hat{p_1}\rangle, \langle\hat{x_2}\rangle, \langle\hat{p_2}\rangle, ..., \langle\hat{x_N}\rangle, \langle\hat{p_N}\rangle) = \Tr[\hat{\rho} \mathbf{\hat{r}}] ,
\end{equation}
and the covariance matrix has components,
\begin{equation} \label{eq:19}
\sigma_{jk} = \langle \mathbf{\hat{r}}_j\mathbf{\hat{r}}_k + \mathbf{\hat{r}}_k\mathbf{\hat{r}}_j \rangle - 2\langle \mathbf{\hat{r}}_j \rangle \langle \mathbf{\hat{r}}_k \rangle = \Tr[\hat{\rho} \{\mathbf{\hat{r_j}} - \mathbf{\bar{r}_j}, \mathbf{\hat{r}_k} - \mathbf{\bar{r}_k}\}].
\end{equation}


The covariance matrix is of central importance as it contains all the necessary information regarding properties such as purity and entanglement. It is an active area of research for many \cite{Adesso07, Plenio03}, and we often choose to isolate the matrix by taking the first moments to be zero ($\mathbf{\bar{r}} = 0$).

Equivalently, Gaussian states can be interpreted as the ground and thermal states of systems with quadratic Hamiltonians \cite{Genoni16}. A quadratic Hamiltonian is defined as one whose position and momenta operators are, at most, quadratic in its definition. The $N$-mode quantum harmonic oscillator is an obvious example where both the momentum and position operators appear quadratically. They can thus be represented in matrix form as follows
\begin{equation} \label{eq:20}
\hat{H} = \frac{1}{2}\mathbf{\hat{r}}^{T}H\mathbf{\hat{r}}+\mathbf{\hat{r}}^{T}\mathbf{a}.
\end{equation}


A state $\hat{\rho}$ is Gaussian if and only if the Hamiltonian matrix $ \mathit{H} > 0$. Physically, this is reasonable as we are only considering stable systems (there must be a stable lower bound on $H$) and, mathematically, $H$ must be positive definite as $\sigma>0$. Therefore, we can equally well define a Gaussian state
\begin{equation} \label{eq:21}
\hat{\rho}_G = \frac{e^{-\beta \hat{H}}}{\Tr[e^{-\beta \hat{H}}]}.
\end{equation}\\
where $\beta = \frac{1}{k_BT}$ and the denominator is included to ensure that $\hat{\rho}_G$ has unit trace as per Eq.\ref{eq:4}. Assuming the linear terms do not contribute significantly to the quadratic Hamiltonian, $\hat{H}$, we can again isolate the quadratic matrix by dropping the linear terms completely \cite{Genoni16}, i.e.
\begin{equation} \label{eq:22}
\hat{H} = \frac{1}{2}\mathbf{\hat{r}}^{T}H\mathbf{\hat{r}}.
\end{equation}

Given the simplicity of this approach, Gaussian states hold a prominent position within many areas of research including optomechanics \cite{Genoni15} and atomic ensembles \cite{Sherson}. There have also been a number of reviews outlining the central role of Gaussian states within CV quantum information processing \cite{Napoli05, Weedbrook12}. 

\subsection{Symplectic Framework}
\label{sec:symplectic}
Gaussian states are associated with the mathematical framework of the real symplectic group, $Sp(2N, \mathbb{R})$ \cite{Arvind95}. This group is characterised by the properties of symplectic transformations. A symplectic transformation is a unitary which maps a Gaussian state to another Gaussian state within the phase space. The (linear) symplectic transformation maps the first moments according to
\begin{equation}\label{eq:23}
\mathbf{\bar{r}}' = S \mathbf{\bar{r}},
\end{equation}
and the second moments
\begin{equation}\label{eq:24}
\sigma' = S\sigma S^T,
\end{equation}
where S is a real, symplectic matrix \cite{Adesso14}.

The set of all real symplectic matrices, $\{S\}$, then form a group within the real, $2N$ dimensional phase space called the symplectic group, $Sp(2N, \mathbb{R})$, that preserve the symplectic form $\Omega$ defined in Eq.\ref{eq:12}
\begin{equation} \label{eq:25}
\Omega = S\Omega S^T .
\end{equation}

For example, a squeezing transformation $S_r$, for $r \in \mathbb{R}$, is given as
\begin{equation*}
S_r = \begin{pmatrix}
e^r & 0  \\
0 & e^{-r} \\
\end{pmatrix}.
\end{equation*}

Then, using Eq.\ref{eq:25} we can see the symplectic form is preserved
\begin{equation*}
S_r\Omega S_r^{T} = \begin{pmatrix}
e^r & 0  \\
0 & e^{-r} \\
\end{pmatrix}
\begin{pmatrix}
0 & 1  \\
-1 & 0 \\
\end{pmatrix}
\begin{pmatrix}
e^r & 0  \\
0 & e^{-r} \\
\end{pmatrix}  = \begin{pmatrix}
0 & e^re^{-r}  \\
-e^{-r}e^r & 0 \\
\end{pmatrix} = \begin{pmatrix}
0 & 1 \\
-1 & 0 \\
\end{pmatrix} = \Omega .
\end{equation*}

Williamson's Theorem \cite{Williamson36} states that for every real, symmetric, positive-definite matrix  $\sigma$ there exists a symplectic transformation $S \in Sp(2N, \mathbb{R})$ that diagonalises $\sigma$
\begin{equation} \label{eq:27}
S\sigma S^T = \nu,
\end{equation}
where $\nu$ are the symplectic eigenvalues of $\sigma$ 
\begin{equation} \label{eq:28}
\nu = \bigoplus_{j=1}^{N} 
\begin{pmatrix}
\nu_j & 0  \\
0 & \nu_j \\
\end{pmatrix}.
\end{equation}

The set of symplectic eigenvalues of $\sigma$ form the symplectic spectrum, $\{\nu_j\}$. These symplectic eigenvalues can also be calculated by considering the (standard, non-symplectic) eigenvalues of $\lvert i\Omega \sigma \lvert$. Furthermore, using the Robertson-Schr{\"o}dinger uncertainty principle outlined in Section \ref{sec:uncertainty} it is possible to show that $\nu_j\geq 1$ for all $j = 1, ..., N$ \cite{Serafini05}.

\subsection{The Uncertainty Principle}
\label{sec:uncertainty}
The covariance matrix, $\sigma$, is the covariance matrix of a quantum state if and only if it satisfies the uncertainty principle \cite{Simon94}. The Robertson-Schr{\"o}dinger uncertainty principle is given as \cite{Rob29, Sch30}
\begin{equation} \label{eq:29}
\sigma + i\Omega \geq 0.
\end{equation} 
We can show that the familiar Heisenberg uncertainty principle is a special case of the Robertson-Schr{\"o}dinger uncertainty principle. For $\mathbf{\hat{r}} = (\hat{x}, \hat{p})^T$, the covariance matrix is given as
\begin{equation*}
\sigma = 
\begin{pmatrix}
\sigma_{xx} & \sigma_{xp}  \\
\sigma_{px} & \sigma_{pp} \\
\end{pmatrix}
= 
\begin{pmatrix}
2\Delta\hat{x}^2 & 0  \\
0 & 2\Delta\hat{p}^2 \\
\end{pmatrix} \qquad\text{where we assume $\sigma_{xp}=\sigma_{px}= \langle \hat{x}\hat{p} + \hat{p}\hat{x} \rangle - 2\bar{x}\bar{p} = 0$}.
\end{equation*}
From Eqs.\ref{eq:12} and \ref{eq:29} we can see
\begin{equation*}
\sigma + i\Omega = 
\begin{pmatrix}
2\Delta\hat{x}^2 & i  \\
-i & 2\Delta\hat{p}^2 \\
\end{pmatrix} \geq 0.
\end{equation*}
Taking the determinant gives
\begin{equation*}
4\Delta\hat{x}^{2}\Delta\hat{p}^2 - 1 \geq 0.
\end{equation*}  
This gives us Heisenberg's uncertainty principle ($\hbar = 1$) \cite{Heisenberg27} 
\begin{equation*}
\Delta\hat{x}^{2}\Delta\hat{p}^2 \geq \frac{1}{4} .
\end{equation*}

\section{Dynamics}
\label{sec:dynamics}
\subsection{The Heisenberg Picture}
Till now, our discussion of the evolution of state has been described in terms of time independent operators acting upon a time varying state. This view of the world is described by the Schr{\"o}dinger picture in which all operators representing observables (Hamiltonian, position, time etc.) are constant in time. In contrast to this, however, the Heisenberg picture assumes the state of the system has no time dependency, rather it is acted upon by time dependent operators.

Clearly, at $t=0$, both the Schr{\"o}dinger picture and the Heisenberg picture will coincide. Furthermore, the Heisenberg equation governs the dynamics of the system entirely analogous to the Schr{\"o}dinger equation \cite{Fujita}.


\subsection{Closed System Dynamics}

A closed system is one which experiences no influence from the external environment. The Heisenberg evolution equation for an operator $\hat{O}$ in a closed system is given by \cite{Fujita}
\begin{equation*}
\frac{d\hat{O}}{dt} = \frac{i}{\hbar}[\hat{H}, \hat{O}].
\end{equation*}

For any system, the vector of canonical operators $\mathbf{\hat{r}}$ evolves under the quadratic Hamiltonian, $\hat{H} = \frac{1}{2} H_{k l}\hat{r_k}\hat{r_l}$, according to \cite{Genoni16} 
\begin{equation}\label{eq:31}
\frac{d \mathbf{\hat{r}}}{dt} = \Omega H \mathbf{\hat{r}},
\end{equation} which has the familiar solution
\begin{equation}\label{eq:32}
\mathbf{\hat{r}}(t) =e^{\Omega H t} \mathbf{\hat{r}}(0) = S\mathbf{\hat{r}}(0) ,
\end{equation}
where $S = e^{\Omega H t}$ is a real, symplectic matrix.

\emph{Proof}
\begin{flalign*}
\frac{d\hat{r_j}}{dt} &= i[\frac{1}{2}H_{kl}\hat{r_k}\hat{r_l}, \hat{r_j}] = \frac{i}{2}H_{kl} [\hat{r_k}\hat{r_l}, \hat{r_j}]&\\
&= \frac{i}{2} H_{kl}(\hat{r_k}[\hat{r_l}, \hat{r_j}] + [\hat{r_k}, \hat{r_j}]\hat{r_l})& \tag*{using $[\hat{AB}, \hat{C}] = \hat{A}[\hat{B},\hat{C}] + [\hat{A},\hat{C}]\hat{B}$}\\
&= \frac{i}{2} H_{kl} (\hat{r_k}(i\Omega_{lj}) + (i\Omega_{kj})\hat{r_l})&\tag*{using Eq.\ref{eq:11}}\\
&= -\frac{1}{2} H_{kl} (\hat{r_k}\Omega_{lj} + \Omega_{kj}\hat{r_l})&\\
&= \frac{1}{2} H_{kl} (\hat{r_k}\Omega_{jl} + \Omega_{jk}\hat{r_l})& \tag*{using $\Omega_{jl} = - \Omega_{lj}$}\\
&= \frac{1}{2} \Omega_{jk}H_{lk}\hat{r_k}  + \frac{1}{2} \Omega_{jk}H_{kl}\hat{r_l}&\\
&= \Omega_{jl}H_{lk}\hat{r_k}& \tag*{using $H_{kl} = H_{lk}$.}&
\end{flalign*}

Hence, as required, we arrive at
\begin{equation*}
\frac{d \mathbf{\hat{r}}}{d t} = \Omega H \mathbf{\hat{r}}
\tag*{\rule{2mm}{2mm}}
\end{equation*}



The symplectic transformations, $S$, introduced in Eqs.\ref{eq:23} and \ref{eq:24} are equivalent to unitary transformations, $\hat{U} = e^{-i\hat{H}t}$, in the Hilbert space. Therefore, the symplectic transformation, $S$, preserves the symplectic form, $\Omega$, as outlined in Section \ref{sec:symplectic} \cite{Wang07}. 

  
\subsection{Open System Dynamics}
Finally, we turn our attention to open system dynamics. As outlined in \cite{Genoni16}, the covariance matrix, $\sigma$, fully characterises the shape of the Gaussian and, therefore, captures all the dynamical properties of interest. We would like to apply these techniques to a quantum system that is under the influence of its external environment. We make the simplifying assumption that the system is Markovian; the evolution of the state is entirely determined by the current state and has no dependence on the state's history. 

The evolution of $\sigma$ is described by
\begin{equation} \label{eq:33}
\frac{d \sigma}{d t} = (\Omega H) \sigma + \sigma(\Omega H)^T  ,
\end{equation}
with the solution
\begin{equation} \label{eq:34}
\sigma(t) = e^{\Omega H t} \sigma(0) (e^{\Omega H t})^T = S\sigma(0)S^T .
\end{equation}

\emph{Proof}
\begin{flalign*}
\frac{d\sigma_{jk}}{dt} &= \frac{d}{dt}(\Tr[\hat{\rho} \{\mathbf{\hat{r_j}}, \mathbf{\hat{r_k}}\}])& \tag*{using Eq.\ref{eq:19} with no linear terms}\\
&= \Tr[\hat{\rho} \frac{d}{dt}(\mathbf{\hat{r_j}}\mathbf{\hat{r_k}} + \mathbf{\hat{r_k}}\mathbf{\hat{r_j}})]& \tag*{\text{as $\hat{\rho}$ has no time dependence}}\\
&= \Tr[\hat{\rho} (\frac{d \mathbf{\hat{r_j}}}{dt} \mathbf{\hat{r_k}} + \mathbf{\hat{r_j}}\frac{d \mathbf{\hat{r_k}}}{d t} +\frac{d \mathbf{\hat{r_k}}}{d t} \mathbf{\hat{r_j}} + \mathbf{\hat{r_k}}\frac{d\mathbf{\hat{r_j}}}{dt})]&\\
&= \Tr[\hat{\rho} (\Omega_{jm}H_{mn}\mathbf{\hat{r_n}\hat{r_k}} + \mathbf{\hat{r_j}}\Omega_{km}H_{mn}\mathbf{\hat{r_n}}  + \Omega_{km}H_{mn}\mathbf{\hat{r_n}\hat{r_j}} + \mathbf{\hat{r_k}}\Omega_{jm}H_{mn}\mathbf{\hat{r_n}} )]&\tag*{\text{using Eq.\ref{eq:31}}}\\
&= \Omega_{jm}H_{mn}\sigma_{nk} + \Omega_{km}H_{mn}\sigma_{jn}&\\
&= (\Omega_{jm}H_{mn})\sigma_{nk} + \sigma_{jn}(\Omega H)_{nk}^T .&
\end{flalign*}

Hence, as required, we arrive at
\begin{equation*}
\frac{d \mathbf{\hat{r}}}{d t} = \Omega H \mathbf{\hat{r}} \tag*{\rule{2mm}{2mm}}
\end{equation*}

For the open system we can state a new equation of motion, the `diffusion equation' \cite{Genoni16}
\begin{equation} \label{eq:35}
\frac{d \sigma}{d t} = A\sigma +\sigma A^{T} + D,
\end{equation} where $A$ and $D$ are the `drift' and `diffusion' matrices respectively. For a coupling, $C$, between the system and the environment, $A$ and $D$ are defined as
\begin{equation} \label{eq:36}
A = \Omega H_S + \frac{\Omega C\Omega C^T}{2}\quad\text{and}\quad D = \Omega C \sigma_{E} C^{T} \Omega^T ,
\end{equation} where $H_S$ refers to the Hamiltonian of the system described by Eq.\ref{eq:22} and $\sigma_E$ is the environment covariance matrix.

\section{Conclusion}
\label{sec:conc}





\bibliography{bib_file}
\bibliographystyle{unsrt}
\end{document}